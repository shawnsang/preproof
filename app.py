import streamlit as st
import os
import json
from datetime import datetime
from dotenv import load_dotenv
from loguru import logger
from llm_processor import LLMProcessor
from text_processor import TextProcessor

# é…ç½®æ—¥å¿—
logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
logger.add(
    "logs/app_{time:YYYY-MM-DD}.log",
    rotation="1 day",
    retention="30 days",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    level="INFO"
)
# æ·»åŠ æ§åˆ¶å°æ—¥å¿—è¾“å‡º
logger.add(
    lambda msg: print(msg, end=""),
    format="{time:HH:mm:ss} | {level} | {message}",
    level="INFO",
    colorize=True
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®ç¼“å­˜æ–‡ä»¶è·¯å¾„
CONFIG_CACHE_FILE = "config_cache.json"

def load_cached_config():
    """åŠ è½½ç¼“å­˜çš„é…ç½®"""
    try:
        if os.path.exists(CONFIG_CACHE_FILE):
            with open(CONFIG_CACHE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        logger.warning(f"åŠ è½½é…ç½®ç¼“å­˜å¤±è´¥: {e}")
    return {}

def save_config_cache(api_key, base_url, model):
    """ä¿å­˜é…ç½®åˆ°ç¼“å­˜"""
    try:
        config = {
            "api_key": api_key,
            "base_url": base_url,
            "model": model,
            "last_updated": datetime.now().isoformat()
        }
        with open(CONFIG_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        logger.info("é…ç½®å·²ä¿å­˜åˆ°ç¼“å­˜")
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®ç¼“å­˜å¤±è´¥: {e}")

def main():
    st.set_page_config(
        page_title="å½•éŸ³æ–‡å­—æ ¡å¯¹åŠ©æ‰‹",
        page_icon="ğŸ“",
        layout="wide"
    )
    
    st.title("ğŸ“ å½•éŸ³æ–‡å­—æ ¡å¯¹åŠ©æ‰‹")
    st.markdown("---")
    
    # åŠ è½½ç¼“å­˜çš„é…ç½®
    cached_config = load_cached_config()
    
    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ LLMé…ç½®")
        
        # ç®€åŒ–çš„LLMé…ç½® - åªä¿ç•™ä¸‰ä¸ªå¿…è¦å‚æ•°
        api_key = st.text_input(
            "API Key", 
            type="password", 
            value=cached_config.get("api_key", os.getenv("OPENAI_API_KEY", "")),
            help="è¾“å…¥ä½ çš„LLMæœåŠ¡APIå¯†é’¥"
        )
        
        base_url = st.text_input(
            "Base URL", 
            value=cached_config.get("base_url", os.getenv("OPENAI_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")),
            help="LLMæœåŠ¡çš„APIåŸºç¡€URL"
        )
        
        model = st.text_input(
            "æ¨¡å‹åç§°", 
            value=cached_config.get("model", "qwen-turbo"),
            placeholder="ä¾‹å¦‚ï¼šqwen-turbo, gpt-3.5-turbo",
            help="è¾“å…¥è¦ä½¿ç”¨çš„æ¨¡å‹åç§°"
        )
        
        # ä¿å­˜é…ç½®æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", help="ä¿å­˜å½“å‰é…ç½®ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨"):
            if api_key and base_url and model:
                save_config_cache(api_key, base_url, model)
                st.success("é…ç½®å·²ä¿å­˜ï¼")
            else:
                st.error("è¯·å¡«å†™å®Œæ•´çš„é…ç½®ä¿¡æ¯")
        
        # æ˜¾ç¤ºä¸Šæ¬¡ä¿å­˜æ—¶é—´
        if cached_config.get("last_updated"):
            st.caption(f"ä¸Šæ¬¡ä¿å­˜: {cached_config['last_updated'][:19].replace('T', ' ')}")
        
        st.markdown("---")
        
        # å¤„ç†å‚æ•°
        st.subheader("å¤„ç†å‚æ•°")
        chunk_size = st.slider("åˆ†æ®µå¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰", 500, 3000, 1500)
        overlap_size = st.slider("é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰", 50, 300, 100)
        

    
    # è¾“å…¥åŒºåŸŸï¼ˆä¸ŠåŠéƒ¨åˆ†ï¼‰
    st.header("ğŸ“„ è¾“å…¥å†…å®¹")
    
    # æ·»åŠ å¤„ç†æ¨¡å¼é€‰æ‹©
    st.subheader("ğŸ”§ å¤„ç†æ¨¡å¼")
    processing_mode = st.radio(
        "é€‰æ‹©å¤„ç†æ¨¡å¼",
        ["å®Œæ•´æ ¡å¯¹æ¨¡å¼", "ç›´æ¥ç¼–è¾‘æ¨¡å¼"],
        help="å®Œæ•´æ ¡å¯¹æ¨¡å¼ï¼šå…ˆè¿›è¡ŒåŸºç¡€æ ¡å¯¹ï¼Œå†è¿›è¡Œç¼–è¾‘æ•´ç†\nç›´æ¥ç¼–è¾‘æ¨¡å¼ï¼šè·³è¿‡åŸºç¡€æ ¡å¯¹ï¼Œç›´æ¥å¯¹å·²æ ¡å¯¹æ–‡ç¨¿è¿›è¡Œç¼–è¾‘æ•´ç†"
    )
    
    # æ ¹æ®æ¨¡å¼æ˜¾ç¤ºä¸åŒçš„æ–‡ä»¶ä¸Šä¼ æç¤º
    if processing_mode == "å®Œæ•´æ ¡å¯¹æ¨¡å¼":
        st.info("ğŸ“ å®Œæ•´æ ¡å¯¹æ¨¡å¼ï¼šé€‚ç”¨äºå½•éŸ³è½¬æ–‡å­—çš„åŸå§‹æ–‡ç¨¿ï¼Œå°†è¿›è¡ŒåŸºç¡€æ ¡å¯¹å’Œç¼–è¾‘æ•´ç†ä¸¤ä¸ªæ­¥éª¤")
        uploaded_file = st.file_uploader("ä¸Šä¼ å½•éŸ³æ–‡å­—æ–‡ä»¶ï¼ˆåŸå§‹æ–‡ç¨¿ï¼‰", type=['txt'])
    else:
        st.info("âœï¸ ç›´æ¥ç¼–è¾‘æ¨¡å¼ï¼šé€‚ç”¨äºå·²ç»å®ŒæˆåŸºç¡€æ ¡å¯¹çš„æ–‡ç¨¿ï¼Œå°†ç›´æ¥è¿›è¡Œç¼–è¾‘æ•´ç†")
        uploaded_file = st.file_uploader("ä¸Šä¼ å·²æ ¡å¯¹æ–‡ç¨¿", type=['txt', 'md'])
    
    # æˆ–è€…ç›´æ¥è¾“å…¥
    if processing_mode == "å®Œæ•´æ ¡å¯¹æ¨¡å¼":
        text_input = st.text_area("æˆ–ç›´æ¥è¾“å…¥å½•éŸ³æ–‡å­—ï¼ˆåŸå§‹æ–‡ç¨¿ï¼‰", height=200)
    else:
        text_input = st.text_area("æˆ–ç›´æ¥è¾“å…¥å·²æ ¡å¯¹æ–‡ç¨¿", height=200)
    
    # é¢†åŸŸçŸ¥è¯†å’Œå…³é”®å­—
    col_input1, col_input2 = st.columns(2)
    with col_input1:
        domain_knowledge = st.text_area("é¢†åŸŸçŸ¥è¯†", placeholder="ä¾‹å¦‚ï¼šè¿™æ˜¯æ˜“ç»ç¦»å¦çš„æè¿°", height=100)
        if st.button("ğŸ” æ‰©å±•é¢†åŸŸçŸ¥è¯†", help="ä½¿ç”¨AIæ‰©å±•å’Œä¼˜åŒ–é¢†åŸŸçŸ¥è¯†"):
            if domain_knowledge.strip() and api_key:
                with st.spinner("æ­£åœ¨æ‰©å±•é¢†åŸŸçŸ¥è¯†..."):
                    try:
                        processor = LLMProcessor(api_key, base_url, model)
                        expanded_domain = processor.expand_domain_knowledge(domain_knowledge)
                        st.session_state.expanded_domain_knowledge = expanded_domain
                        st.success("é¢†åŸŸçŸ¥è¯†æ‰©å±•å®Œæˆï¼")
                    except Exception as e:
                        st.error(f"æ‰©å±•å¤±è´¥: {str(e)}")
            elif not domain_knowledge.strip():
                st.warning("è¯·å…ˆè¾“å…¥é¢†åŸŸçŸ¥è¯†")
            else:
                st.error("è¯·å…ˆé…ç½®API Key")
        
        # æ˜¾ç¤ºæ‰©å±•åçš„é¢†åŸŸçŸ¥è¯†
        if 'expanded_domain_knowledge' in st.session_state:
            st.text_area("æ‰©å±•åçš„é¢†åŸŸçŸ¥è¯†", value=st.session_state.expanded_domain_knowledge, height=150, disabled=True)
    
    with col_input2:
        keywords = st.text_area("å…³é”®å­—", placeholder="ä¾‹å¦‚ï¼šç¦»å¦,åå¦,å…«å¦", height=100)
        if st.button("ğŸ” æ‰©å±•å…³é”®å­—", help="ä½¿ç”¨AIæ‰©å±•å’Œè¡¥å…¨å…³é”®å­—"):
            if keywords.strip() and api_key:
                with st.spinner("æ­£åœ¨æ‰©å±•å…³é”®å­—..."):
                    try:
                        processor = LLMProcessor(api_key, base_url, model)
                        # ä½¿ç”¨æ‰©å±•åçš„é¢†åŸŸçŸ¥è¯†ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                        reference_domain = st.session_state.get('expanded_domain_knowledge', domain_knowledge)
                        expanded_keywords = processor.expand_keywords(keywords, reference_domain)
                        st.session_state.expanded_keywords = expanded_keywords
                        st.success("å…³é”®å­—æ‰©å±•å®Œæˆï¼")
                    except Exception as e:
                        st.error(f"æ‰©å±•å¤±è´¥: {str(e)}")
            elif not keywords.strip():
                st.warning("è¯·å…ˆè¾“å…¥å…³é”®å­—")
            else:
                st.error("è¯·å…ˆé…ç½®API Key")
        
        # æ˜¾ç¤ºæ‰©å±•åçš„å…³é”®å­—
        if 'expanded_keywords' in st.session_state:
            st.text_area("æ‰©å±•åçš„å…³é”®å­—", value=st.session_state.expanded_keywords, height=150, disabled=True)
    
    # å¤„ç†æŒ‰é’®
    button_text = "å¼€å§‹æ ¡å¯¹" if processing_mode == "å®Œæ•´æ ¡å¯¹æ¨¡å¼" else "å¼€å§‹ç¼–è¾‘"
    if st.button(button_text, type="primary"):
        # è·å–è¾“å…¥æ–‡æœ¬
        input_text = ""
        if uploaded_file is not None:
            input_text = uploaded_file.read().decode('utf-8')
            logger.info(f"ä¸Šä¼ æ–‡ä»¶ï¼Œæ–‡æœ¬é•¿åº¦: {len(input_text)} å­—ç¬¦")
        elif text_input:
            input_text = text_input
            logger.info(f"ç›´æ¥è¾“å…¥æ–‡æœ¬ï¼Œé•¿åº¦: {len(input_text)} å­—ç¬¦")
        
        if input_text and api_key:
            # è·å–æ‰©å±•åçš„é¢†åŸŸçŸ¥è¯†å’Œå…³é”®å­—ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            final_domain_knowledge = st.session_state.get('expanded_domain_knowledge', domain_knowledge)
            final_keywords = st.session_state.get('expanded_keywords', keywords)
            
            # æ ¹æ®å¤„ç†æ¨¡å¼è°ƒç”¨ä¸åŒçš„å‡½æ•°
            if processing_mode == "å®Œæ•´æ ¡å¯¹æ¨¡å¼":
                process_text(input_text, final_domain_knowledge, final_keywords, api_key, base_url, model, chunk_size, overlap_size)
            else:
                process_direct_edit(input_text, final_domain_knowledge, final_keywords, api_key, base_url, model)
        else:
            error_msg = "è¯·æä¾›æ–‡æœ¬å†…å®¹å’ŒAPI Key" if processing_mode == "å®Œæ•´æ ¡å¯¹æ¨¡å¼" else "è¯·æä¾›å·²æ ¡å¯¹æ–‡ç¨¿å’ŒAPI Key"
            st.error(error_msg)
            logger.error("ç¼ºå°‘å¿…è¦å‚æ•°ï¼šæ–‡æœ¬å†…å®¹æˆ–API Key")
    
    st.markdown("---")
    
    # ç»“æœåŒºåŸŸï¼ˆä¸‹åŠéƒ¨åˆ†ï¼‰
    st.header("ğŸ“‹ å¤„ç†ç»“æœ")
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœçš„æ ‡ç­¾é¡µ
    if 'basic_result' in st.session_state or 'edited_result' in st.session_state:
        tab1, tab2, tab3 = st.tabs(["åŸºç¡€æ ¡å¯¹ç‰ˆæœ¬", "ç¼–è¾‘æ•´ç†ç‰ˆæœ¬", "å¯¹æ¯”æŸ¥çœ‹"])
        
        with tab1:
            if 'basic_result' in st.session_state:
                # ä½¿ç”¨å®¹å™¨ç¡®ä¿å®Œæ•´æ˜¾ç¤º
                with st.container():
                    st.markdown("### åŸºç¡€æ ¡å¯¹ç»“æœ")
                    # ä½¿ç”¨expanderæ¥å¤„ç†é•¿æ–‡æœ¬
                    with st.expander("æŸ¥çœ‹å®Œæ•´å†…å®¹", expanded=True):
                        st.markdown(st.session_state.basic_result, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºæ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
                    st.info(f"æ–‡æœ¬é•¿åº¦: {len(st.session_state.basic_result)} å­—ç¬¦")
                    
                    st.download_button(
                        "ä¸‹è½½åŸºç¡€æ ¡å¯¹ç‰ˆæœ¬",
                        st.session_state.basic_result,
                        "basic_proofread.md",
                        "text/markdown"
                    )
        
        with tab2:
            if 'edited_result' in st.session_state:
                # ä½¿ç”¨å®¹å™¨ç¡®ä¿å®Œæ•´æ˜¾ç¤º
                with st.container():
                    st.markdown("### ç¼–è¾‘æ•´ç†ç»“æœ")
                    # ä½¿ç”¨expanderæ¥å¤„ç†é•¿æ–‡æœ¬
                    with st.expander("æŸ¥çœ‹å®Œæ•´å†…å®¹", expanded=True):
                        st.markdown(st.session_state.edited_result, unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºæ–‡æœ¬ç»Ÿè®¡ä¿¡æ¯
                    st.info(f"æ–‡æœ¬é•¿åº¦: {len(st.session_state.edited_result)} å­—ç¬¦")
                    
                    st.download_button(
                        "ä¸‹è½½ç¼–è¾‘æ•´ç†ç‰ˆæœ¬",
                        st.session_state.edited_result,
                        "edited_version.md",
                        "text/markdown"
                    )
        
        with tab3:
            if 'basic_result' in st.session_state and 'edited_result' in st.session_state:
                st.markdown("### å¯¹æ¯”æŸ¥çœ‹")
                col_basic, col_edited = st.columns(2)
                
                with col_basic:
                    st.subheader("åŸºç¡€æ ¡å¯¹ç‰ˆæœ¬")
                    with st.container():
                        # é™åˆ¶é«˜åº¦å¹¶æ·»åŠ æ»šåŠ¨
                        st.markdown(
                            f'<div style="height: 600px; overflow-y: auto; border: 1px solid #ddd; padding: 10px; border-radius: 5px;">'
                            f'{st.session_state.basic_result}'
                            f'</div>',
                            unsafe_allow_html=True
                        )
                        st.info(f"é•¿åº¦: {len(st.session_state.basic_result)} å­—ç¬¦")
                
                with col_edited:
                    st.subheader("ç¼–è¾‘æ•´ç†ç‰ˆæœ¬")
                    with st.container():
                        # é™åˆ¶é«˜åº¦å¹¶æ·»åŠ æ»šåŠ¨
                        st.markdown(
                            f'<div style="height: 600px; overflow-y: auto; border: 1px solid #ddd; padding: 10px; border-radius: 5px;">'
                            f'{st.session_state.edited_result}'
                            f'</div>',
                            unsafe_allow_html=True
                        )
                        st.info(f"é•¿åº¦: {len(st.session_state.edited_result)} å­—ç¬¦")
    else:
        st.info("è¯·åœ¨ä¸Šæ–¹è¾“å…¥å½•éŸ³æ–‡å­—å¹¶ç‚¹å‡»\"å¼€å§‹æ ¡å¯¹\"æŒ‰é’®")

def process_text(input_text, domain_knowledge, keywords, api_key, base_url, model, chunk_size, overlap_size):
    """å¤„ç†æ–‡æœ¬çš„ä¸»è¦å‡½æ•°"""
    try:
        logger.info(f"å¼€å§‹å¤„ç†æ–‡æœ¬ï¼Œä½¿ç”¨æ¨¡å‹: {model}")
        logger.info(f"é¢†åŸŸçŸ¥è¯†: {domain_knowledge}")
        logger.info(f"å…³é”®å­—: {keywords}")
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        llm_processor = LLMProcessor(api_key, base_url, model)
        text_processor = TextProcessor(chunk_size, overlap_size)
        
        # æ˜¾ç¤ºè¿›åº¦
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
            progress_text = st.empty()
        
        # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€æ ¡å¯¹
        status_text.text("æ­£åœ¨è¿›è¡ŒåŸºç¡€æ ¡å¯¹...")
        logger.info("å¼€å§‹åŸºç¡€æ ¡å¯¹é˜¶æ®µ")
        
        # åˆ†æ®µå¤„ç†
        chunks = text_processor.split_text(input_text)
        total_chunks = len(chunks)
        logger.info(f"æ–‡æœ¬åˆ†ä¸º {total_chunks} ä¸ªæ®µè½")
        
        basic_results = []
        
        for i, chunk in enumerate(chunks):
            current_progress = 25 + (i * 50 // total_chunks)
            progress_bar.progress(current_progress)
            progress_text.text(f"åŸºç¡€æ ¡å¯¹è¿›åº¦: {i+1}/{total_chunks}")
            
            logger.info(f"å¤„ç†ç¬¬ {i+1}/{total_chunks} ä¸ªæ®µè½")
            chunk_result = llm_processor.basic_proofread(chunk, domain_knowledge, keywords)
            basic_results.append(chunk_result)
        
        # åˆå¹¶åŸºç¡€æ ¡å¯¹ç»“æœ
        basic_result = text_processor.merge_results(basic_results)
        st.session_state.basic_result = basic_result
        
        # ä¿å­˜åŸºç¡€æ ¡å¯¹ç»“æœåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        with open(f"logs/basic_proofread_{timestamp}.md", "w", encoding="utf-8") as f:
            f.write(basic_result)
        logger.info(f"åŸºç¡€æ ¡å¯¹ç»“æœå·²ä¿å­˜åˆ°: logs/basic_proofread_{timestamp}.md")
        
        # ç¬¬äºŒæ­¥ï¼šç¼–è¾‘æ•´ç†
        status_text.text("æ­£åœ¨è¿›è¡Œç¼–è¾‘æ•´ç†...")
        progress_text.text("ç¼–è¾‘æ•´ç†è¿›åº¦: 1/1")
        progress_bar.progress(75)
        logger.info("å¼€å§‹ç¼–è¾‘æ•´ç†é˜¶æ®µ")
        
        edited_result = llm_processor.edit_and_organize(basic_result, domain_knowledge, keywords)
        st.session_state.edited_result = edited_result
        
        # ä¿å­˜ç¼–è¾‘æ•´ç†ç»“æœåˆ°æ–‡ä»¶
        with open(f"logs/edited_version_{timestamp}.md", "w", encoding="utf-8") as f:
            f.write(edited_result)
        logger.info(f"ç¼–è¾‘æ•´ç†ç»“æœå·²ä¿å­˜åˆ°: logs/edited_version_{timestamp}.md")
        
        progress_bar.progress(100)
        status_text.text("å¤„ç†å®Œæˆï¼")
        progress_text.text("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
        
        st.success("æ–‡å­—æ ¡å¯¹å®Œæˆï¼è¯·æŸ¥çœ‹ä¸‹æ–¹ç»“æœã€‚")
        logger.success("æ–‡å­—æ ¡å¯¹å¤„ç†å®Œæˆ")
        
    except Exception as e:
        error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
        st.error(error_msg)
        logger.error(error_msg)

def process_direct_edit(input_text, domain_knowledge, keywords, api_key, base_url, model):
    """ç›´æ¥ç¼–è¾‘å¤„ç†å‡½æ•°ï¼Œè·³è¿‡åŸºç¡€æ ¡å¯¹æ­¥éª¤"""
    try:
        logger.info(f"å¼€å§‹ç›´æ¥ç¼–è¾‘å¤„ç†ï¼Œä½¿ç”¨æ¨¡å‹: {model}")
        logger.info(f"é¢†åŸŸçŸ¥è¯†: {domain_knowledge}")
        logger.info(f"å…³é”®å­—: {keywords}")
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        llm_processor = LLMProcessor(api_key, base_url, model)
        
        # æ˜¾ç¤ºè¿›åº¦
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
            progress_text = st.empty()
        
        # ç›´æ¥è¿›è¡Œç¼–è¾‘æ•´ç†
        status_text.text("æ­£åœ¨è¿›è¡Œç¼–è¾‘æ•´ç†...")
        progress_text.text("ç¼–è¾‘æ•´ç†è¿›åº¦: 1/1")
        progress_bar.progress(50)
        logger.info("å¼€å§‹ç¼–è¾‘æ•´ç†é˜¶æ®µï¼ˆç›´æ¥ç¼–è¾‘æ¨¡å¼ï¼‰")
        
        # å°†è¾“å…¥æ–‡æœ¬ä½œä¸ºåŸºç¡€æ ¡å¯¹ç»“æœä¿å­˜ï¼ˆç”¨äºå¯¹æ¯”æŸ¥çœ‹ï¼‰
        st.session_state.basic_result = input_text
        
        # ç›´æ¥è°ƒç”¨ç¼–è¾‘æ•´ç†åŠŸèƒ½
        edited_result = llm_processor.edit_and_organize(input_text, domain_knowledge, keywords)
        st.session_state.edited_result = edited_result
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        with open(f"logs/direct_edit_{timestamp}.md", "w", encoding="utf-8") as f:
            f.write(edited_result)
        logger.info(f"ç›´æ¥ç¼–è¾‘ç»“æœå·²ä¿å­˜åˆ°: logs/direct_edit_{timestamp}.md")
        
        progress_bar.progress(100)
        status_text.text("ç¼–è¾‘å®Œæˆï¼")
        progress_text.text("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆ")
        
        st.success("æ–‡ç¨¿ç¼–è¾‘å®Œæˆï¼è¯·æŸ¥çœ‹ä¸‹æ–¹ç»“æœã€‚")
        logger.success("ç›´æ¥ç¼–è¾‘å¤„ç†å®Œæˆ")
        
    except Exception as e:
        error_msg = f"ç¼–è¾‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
        st.error(error_msg)
        logger.error(error_msg)

if __name__ == "__main__":
    # ç¡®ä¿logsç›®å½•å­˜åœ¨
    os.makedirs("logs", exist_ok=True)
    main()