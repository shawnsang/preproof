import re
from typing import List, Dict, Tuple
from loguru import logger


class MergingProcessor:
    """æ™ºèƒ½åˆå¹¶å¤„ç†å™¨ï¼Œè´Ÿè´£åˆå¹¶ç¼–è¾‘åçš„æ–‡æœ¬å—"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆå¹¶å¤„ç†å™¨"""
        logger.info("åˆå§‹åŒ–æ™ºèƒ½åˆå¹¶å¤„ç†å™¨")

    def merge_edited_chunks(self, edited_results: List[Dict]) -> Dict:
        """
        åˆå¹¶ç¼–è¾‘åçš„æ–‡æœ¬å—
        
        Args:
            edited_results: ç¼–è¾‘ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«contentã€titlesã€golden_quotesç­‰
            
        Returns:
            åˆå¹¶ç»“æœå­—å…¸ï¼ŒåŒ…å«æœ€ç»ˆå†…å®¹ã€æ ‡é¢˜ç»“æ„ã€é‡‘å¥ç­‰
        """
        if not edited_results:
            logger.warning("æ²¡æœ‰ç¼–è¾‘ç»“æœéœ€è¦åˆå¹¶")
            return {'content': '', 'titles': [], 'golden_quotes': []}
        
        if len(edited_results) == 1:
            logger.info("åªæœ‰ä¸€ä¸ªæ–‡æœ¬å—ï¼Œç›´æ¥è¿”å›")
            return {
                'content': edited_results[0]['content'],
                'titles': edited_results[0]['titles'],
                'golden_quotes': edited_results[0]['golden_quotes']
            }
        
        logger.info(f"å¼€å§‹åˆå¹¶ {len(edited_results)} ä¸ªç¼–è¾‘ç»“æœ")
        
        # åˆå¹¶å†…å®¹
        merged_content = self._merge_content(edited_results)
        
        # åˆå¹¶æ ‡é¢˜ç»“æ„
        merged_titles = self._merge_titles(edited_results)
        
        # åˆå¹¶é‡‘å¥
        merged_golden_quotes = self._merge_golden_quotes(edited_results)
        
        # ä¼˜åŒ–åˆå¹¶åçš„å†…å®¹
        optimized_content = self._optimize_merged_content(merged_content, merged_golden_quotes)
        
        result = {
            'content': optimized_content,
            'titles': merged_titles,
            'golden_quotes': merged_golden_quotes
        }
        
        logger.success(f"åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(optimized_content)} å­—ç¬¦")
        return result

    def _merge_content(self, edited_results: List[Dict]) -> str:
        """åˆå¹¶æ–‡æœ¬å†…å®¹"""
        merged_parts = []
        
        for i, result in enumerate(edited_results):
            content = result['content'].strip()
            
            if i == 0:
                # ç¬¬ä¸€å—ç›´æ¥æ·»åŠ 
                merged_parts.append(content)
            else:
                # åç»­å—éœ€è¦å¤„ç†é‡å¤æ ‡é¢˜å’Œè¿æ¥
                processed_content = self._process_subsequent_chunk(content, merged_parts[-1])
                merged_parts.append(processed_content)
        
        # ç”¨åŒæ¢è¡Œè¿æ¥å„éƒ¨åˆ†
        merged_content = '\n\n'.join(merged_parts)
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        merged_content = re.sub(r'\n{3,}', '\n\n', merged_content)
        
        return merged_content.strip()

    def _process_subsequent_chunk(self, content: str, previous_content: str) -> str:
        """å¤„ç†åç»­æ–‡æœ¬å—ï¼Œé¿å…é‡å¤æ ‡é¢˜"""
        lines = content.split('\n')
        processed_lines = []
        
        # è·å–å‰ä¸€å—çš„æœ€åå‡ è¡Œï¼Œç”¨äºæ£€æµ‹é‡å¤
        prev_lines = previous_content.split('\n')[-3:]
        prev_text = '\n'.join(prev_lines).lower()
        
        skip_lines = 0
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            
            # è·³è¿‡å¼€å¤´çš„ç©ºè¡Œ
            if not line_stripped and not processed_lines:
                continue
            
            # æ£€æµ‹æ˜¯å¦æ˜¯é‡å¤çš„æ ‡é¢˜æˆ–å†…å®¹
            if i < 3 and line_stripped:  # åªæ£€æŸ¥å‰3è¡Œ
                if self._is_duplicate_line(line_stripped, prev_text):
                    skip_lines = i + 1
                    continue
            
            # å¦‚æœå·²ç»ç¡®å®šè¦è·³è¿‡çš„è¡Œæ•°ï¼Œç»§ç»­è·³è¿‡
            if i < skip_lines:
                continue
            
            processed_lines.append(line)
        
        return '\n'.join(processed_lines).strip()

    def _is_duplicate_line(self, line: str, previous_text: str) -> bool:
        """æ£€æµ‹æ˜¯å¦æ˜¯é‡å¤çš„è¡Œ"""
        line_lower = line.lower().strip()
        
        # å¿½ç•¥æ ‡é¢˜æ ‡è®°
        line_clean = re.sub(r'^#+\s*', '', line_lower)
        
        # å¦‚æœè¡Œå¤ªçŸ­ï¼Œä¸è®¤ä¸ºæ˜¯é‡å¤
        if len(line_clean) < 5:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å‰é¢çš„å†…å®¹ä¸­å‡ºç°è¿‡
        return line_clean in previous_text

    def _merge_titles(self, edited_results: List[Dict]) -> List[Dict]:
        """åˆå¹¶æ ‡é¢˜ç»“æ„"""
        all_titles = []
        
        for result in edited_results:
            titles = result.get('titles', [])
            all_titles.extend(titles)
        
        # å»é‡ç›¸ä¼¼æ ‡é¢˜
        unique_titles = self._deduplicate_titles(all_titles)
        
        logger.info(f"æ ‡é¢˜åˆå¹¶å®Œæˆï¼Œå…± {len(unique_titles)} ä¸ªæ ‡é¢˜")
        return unique_titles

    def _deduplicate_titles(self, titles: List[Dict]) -> List[Dict]:
        """å»é‡ç›¸ä¼¼æ ‡é¢˜"""
        if not titles:
            return []
        
        unique_titles = []
        seen_titles = set()
        
        for title_info in titles:
            title = title_info['title'].strip()
            title_clean = re.sub(r'[^\w\u4e00-\u9fff]', '', title.lower())
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸ä¼¼æ ‡é¢˜
            is_duplicate = False
            for seen in seen_titles:
                if self._titles_similar(title_clean, seen):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_titles.append(title_info)
                seen_titles.add(title_clean)
        
        return unique_titles

    def _titles_similar(self, title1: str, title2: str) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªæ ‡é¢˜æ˜¯å¦ç›¸ä¼¼"""
        if not title1 or not title2:
            return False
        
        # å®Œå…¨ç›¸åŒ
        if title1 == title2:
            return True
        
        # ä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ªï¼Œä¸”é•¿åº¦å·®ä¸å¤§
        if len(title1) > 0 and len(title2) > 0:
            longer = title1 if len(title1) > len(title2) else title2
            shorter = title2 if len(title1) > len(title2) else title1
            
            if shorter in longer and len(longer) - len(shorter) <= 3:
                return True
        
        return False

    def _merge_golden_quotes(self, edited_results: List[Dict]) -> List[str]:
        """åˆå¹¶é‡‘å¥"""
        all_quotes = []
        
        for result in edited_results:
            quotes = result.get('golden_quotes', [])
            all_quotes.extend(quotes)
        
        # å»é‡ç›¸ä¼¼é‡‘å¥
        unique_quotes = self._deduplicate_quotes(all_quotes)
        
        logger.info(f"é‡‘å¥åˆå¹¶å®Œæˆï¼Œå…± {len(unique_quotes)} ä¸ªé‡‘å¥")
        return unique_quotes

    def _deduplicate_quotes(self, quotes: List[str]) -> List[str]:
        """å»é‡ç›¸ä¼¼é‡‘å¥"""
        if not quotes:
            return []
        
        unique_quotes = []
        
        for quote in quotes:
            quote = quote.strip()
            if not quote:
                continue
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸ä¼¼é‡‘å¥
            is_duplicate = False
            for existing in unique_quotes:
                if self._quotes_similar(quote, existing):
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_quotes.append(quote)
        
        return unique_quotes

    def _quotes_similar(self, quote1: str, quote2: str) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªé‡‘å¥æ˜¯å¦ç›¸ä¼¼"""
        if not quote1 or not quote2:
            return False
        
        # å»é™¤æ ‡ç‚¹ç¬¦å·è¿›è¡Œæ¯”è¾ƒ
        clean1 = re.sub(r'[^\w\u4e00-\u9fff]', '', quote1)
        clean2 = re.sub(r'[^\w\u4e00-\u9fff]', '', quote2)
        
        # å®Œå…¨ç›¸åŒ
        if clean1 == clean2:
            return True
        
        # ä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ªï¼Œä¸”é•¿åº¦å·®ä¸å¤§
        if len(clean1) > 10 and len(clean2) > 10:
            longer = clean1 if len(clean1) > len(clean2) else clean2
            shorter = clean2 if len(clean1) > len(clean2) else clean1
            
            if shorter in longer and len(longer) - len(shorter) <= 5:
                return True
        
        return False

    def _optimize_merged_content(self, content: str, golden_quotes: List[str]) -> str:
        """ä¼˜åŒ–åˆå¹¶åçš„å†…å®¹"""
        # ç¡®ä¿é‡‘å¥éƒ¨åˆ†åœ¨æœ€å
        if golden_quotes:
            # ç§»é™¤ç°æœ‰çš„é‡‘å¥éƒ¨åˆ†
            content = re.sub(r'##\s*ğŸ’\s*ç²¾å½©é‡‘å¥.*?(?=\n##|\Z)', '', content, flags=re.DOTALL)
            
            # åœ¨æœ€åæ·»åŠ é‡‘å¥éƒ¨åˆ†
            quotes_section = "\n\n## ğŸ’ ç²¾å½©é‡‘å¥\n"
            for quote in golden_quotes:
                quotes_section += f"- {quote}\n"
            
            content = content.rstrip() + quotes_section
        
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        # ç¡®ä¿æ ‡é¢˜å‰åæœ‰é€‚å½“çš„ç©ºè¡Œ
        content = re.sub(r'\n(#{1,3}\s)', r'\n\n\1', content)
        content = re.sub(r'(#{1,3}\s[^\n]+)\n([^\n#])', r'\1\n\n\2', content)
        
        return content.strip()

    def create_content_summary(self, merged_result: Dict) -> str:
        """åˆ›å»ºå†…å®¹æ‘˜è¦"""
        content = merged_result['content']
        titles = merged_result['titles']
        golden_quotes = merged_result['golden_quotes']
        
        summary_parts = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        word_count = len(content)
        title_count = len(titles)
        quote_count = len(golden_quotes)
        
        summary_parts.append(f"ğŸ“Š å†…å®¹ç»Ÿè®¡ï¼š{word_count} å­—ç¬¦ï¼Œ{title_count} ä¸ªæ ‡é¢˜ï¼Œ{quote_count} ä¸ªé‡‘å¥")
        
        # æ ‡é¢˜ç»“æ„
        if titles:
            summary_parts.append("\nğŸ“‹ å†…å®¹ç»“æ„ï¼š")
            for title_info in titles[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªæ ‡é¢˜
                level = title_info['level']
                title = title_info['title']
                indent = "  " * (level - 1)
                summary_parts.append(f"{indent}- {title}")
            
            if len(titles) > 10:
                summary_parts.append(f"  ... è¿˜æœ‰ {len(titles) - 10} ä¸ªæ ‡é¢˜")
        
        # ç²¾å½©é‡‘å¥é¢„è§ˆ
        if golden_quotes:
            summary_parts.append("\nğŸ’ ç²¾å½©é‡‘å¥é¢„è§ˆï¼š")
            for quote in golden_quotes[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªé‡‘å¥
                summary_parts.append(f"- {quote}")
            
            if len(golden_quotes) > 3:
                summary_parts.append(f"- ... è¿˜æœ‰ {len(golden_quotes) - 3} ä¸ªé‡‘å¥")
        
        return '\n'.join(summary_parts)